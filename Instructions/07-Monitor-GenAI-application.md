---
lab:
  title: 생성형 AI 애플리케이션 모니터링
  description: 배포된 모델과의 상호 작용을 모니터링하고 생성형 AI 애플리케이션을 사용하여 사용량을 최적화하는 방안에 대한 인사이트를 얻는 방법을 알아봅니다.
---

# 생성형 AI 애플리케이션 모니터링

이 연습에는 약 **30**분이 소요됩니다.

> **참고**: 이 연습에서는 Azure AI 파운드리에 대해 잘 알고 있다고 가정하므로 일부 지침은 보다 적극적인 탐색 및 실습 학습을 장려하기 위해 의도적으로 상세히 설명되어 있지 않습니다.

## 소개

이 연습에서는 채팅 완료 앱에 대한 모니터링을 사용하도록 설정하고 Azure Monitor에서 해당 성능을 확인합니다. 배포된 모델과 상호 작용하여 데이터를 생성하고, 생성형 AI 애플리케이션 대시보드에 대한 인사이트를 통해 생성된 데이터를 보고, 모델의 배포를 최적화하는 데 도움이 되는 경고를 설정합니다

## 환경 설정

이 연습의 작업을 완료하려면 다음이 필요합니다.

- Azure AI 파운드리 허브,
- Azure AI 파운드리 프로젝트,
- 배포된 모델(예: GPT-4o),
- 연결된 Application Insights 리소스.

### AI 파운드리 허브 및 프로젝트 만들기

허브와 프로젝트를 빠르게 설정하기 위해 Azure AI 파운드리 포털 UI를 사용하는 간단한 지침이 아래에 제공됩니다.

1. 웹 브라우저에서 [Azure AI 파운드리 포털](https://ai.azure.com)(`https://ai.azure.com`)을 열고 Azure 자격 증명을 사용하여 로그인합니다.
1. 홈페이지에서 **+ 프로젝트 만들기**를 선택합니다.
1. **프로젝트 만들기** 마법사에서 유효한 프로젝트 이름을 입력하고 기존 허브가 추천되면 새 허브를 만드는 옵션을 선택합니다. 그런 다음 허브 및 프로젝트를 지원하기 위해 자동으로 만들어지는 Azure 리소스를 검토합니다.
1. **사용자 지정**을 선택하고 허브에 대해 다음 설정을 지정합니다.
    - **허브 이름**: *허브에서 유효한 이름*
    - **구독**: ‘Azure 구독’
    - **리소스 그룹**: ‘리소스 그룹 만들기 또는 선택’
    - **위치**: **선택 도움말**을 선택한 다음 위치 도우미 창에서 **gpt-4o**를 선택하고 권장되는 지역을 사용합니다.\*
    - **Azure AI 서비스 또는 Azure OpenAI 연결**: *새 AI 서비스 리소스 만들기*
    - **Azure AI 검색 연결**: 연결 건너뛰기

    > \*Azure OpenAI 리소스는 지역 모델 할당량에 의해 제약을 받습니다. 연습 후반부에 할당량 한도를 초과하는 경우 다른 지역에서 다른 리소스를 만들어야 할 수도 있습니다.

1. **다음**을 선택하여 구성을 검토합니다. **만들기**를 선택하고 프로세스가 완료될 때까지 기다립니다.

### 모델 배포

모니터링할 수 있는 데이터를 생성하려면 먼저 모델을 배포하고 상호 작용해야 합니다. 지침에서는 GPT-4o 모델을 배포하라는 메시지가 표시되지만 사용 가능한 Azure OpenAI Service 컬렉션의 **모든 모델을 사용할 수 있습니다**.

1. 왼쪽 메뉴에서 **내 자산**에서 **모델 + 엔드포인트** 페이지를 선택합니다.
1. **+ 모델 배포** 메뉴에서 **기본 모델 배포**를 선택합니다.
1. 목록에서 **gpt-4o** 모델을 선택하고 배포 세부 정보에서 **사용자 지정**을 선택하고, 다음 설정을 사용하여 배포합니다.
    - **배포 이름**: *모델 배포에 대한 고유한 이름*
    - **배포 유형**: 표준
    - **자동 버전 업데이트**: 사용
    - **모델 버전**: *사용 가능한 최신 버전 선택*
    - **연결된 AI 리소스**: *Azure OpenAI 리소스 연결 선택*
    - **분당 토큰 속도 제한(천)**: 1,000
    - **콘텐츠 필터**: DefaultV2
    - **동적 할당량 사용**: 사용할 수 없음

    > **참고**: TPM을 줄이면 사용 중인 구독에서 사용 가능한 할당량을 과도하게 사용하지 않을 수 있습니다. 이 연습에 사용되는 데이터는 1,000TPM이면 충분합니다. 사용 가능한 할당량이 이 수치 이하이면 연습을 완료할 수 있지만 속도 제한을 초과하는 경우 오류가 발생할 수 있습니다.

1. 배포가 완료될 때가지 기다립니다.

### Application Insights 연결

Application Insights를 Azure AI 파운드리의 프로젝트에 연결하여 모니터링을 위해 데이터 수집을 시작합니다.

1. 왼쪽 메뉴에서 **추적** 페이지를 선택합니다.
1. **앱에 연결할 새** Application Insights 리소스를 만듭니다.
1. Application Insights 리소스 이름을 입력하고 **만들기**를 선택합니다.

이제 Application Insights가 프로젝트에 연결되었으며 분석을 위해 데이터가 수집되기 시작합니다.

## 배포된 모델과 상호 작용

Azure Cloud Shell을 사용하여 Azure AI 파운드리 프로젝트에 연결을 설정하여 배포된 모델과 프로그래밍 방식으로 상호 작용합니다. 이렇게 하면 모델에 프롬프트를 보내고 모니터링 데이터를 생성할 수 있습니다.

### Cloud Shell을 통해 모델과 연결

먼저 모델과 상호 작용하기 위해 인증하는 데 필요한 정보를 검색합니다. 그런 다음 Azure Cloud Shell에 액세스하고 구성을 업데이트하여 제공된 프롬프트를 배포된 사용자 고유의 모델로 보냅니다.

1. Azure AI 파운드리 포털에서 프로젝트의 **개요** 페이지를 봅니다.
1. **프로젝트 세부 정보** 영역에서 **프로젝트 연결 문자열**을 확인합니다.
1. 메모장에 문자열을 **저장**합니다. 이 연결 문자열 사용하여 클라이언트 응용 프로그램에서 프로젝트에 연결합니다.
1. 새 브라우저 탭을 엽니다(Azure AI 파운드리 포털을 기존 탭에서 열어 두기).
1. 새 탭에서 [Azure Portal](https://portal.azure.com)(`https://portal.azure.com`)로 이동한 다음 메시지가 나타나면 Azure 자격 증명을 사용하여 로그인합니다.
1. 페이지 상단의 검색 창 오른쪽에 있는 **[\>_]** 단추를 사용하여 Azure Portal에서 새 Cloud Shell을 만들고 구독에 저장소가 없는 ***PowerShell*** 환경을 선택합니다.
1. Cloud Shell 도구 모음의 **설정** 메뉴에서 **클래식 버전으로 이동**을 선택합니다.

    **<font color="red">계속하기 전에 Cloud Shell의 클래식 버전으로 전환했는지 확인합니다.</font>**

1. Cloud Shell 창에서 다음 명령을 입력하여 실행합니다.

    ```
    rm -r mslearn-genaiops -f
    git clone https://github.com/microsoftlearning/mslearn-genaiops mslearn-genaiops
    ```

    이 명령은 이 연습의 코드 파일이 포함된 GitHub 리포지토리를 복제합니다.

    > **팁**: CloudShell에 명령을 붙여넣으면 출력이 화면 버퍼의 많은 부분을 차지할 수 있습니다. `cls` 명령을 입력해 화면을 지우면 각 작업에 더 집중할 수 있습니다.

1. 리포지토리가 복제된 후 애플리케이션 코드 파일이 포함된 폴더로 이동합니다.  

    ```
   cd mslearn-genaiops/Files/07
    ```

1. Cloud Shell 명령줄 창에서 다음 명령을 입력하여 필요한 라이브러리를 설치합니다.

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-identity azure-ai-projects azure-ai-inference azure-monitor-opentelemetry
    ```

1. 제공된 구성 파일을 열려면 다음 명령을 입력합니다.

    ```
   code .env
    ```

    코드 편집기에서 파일이 열립니다.

1. 코드 파일에서:

    1. **your_project_connection_string** 자리 표시자를 프로젝트의 연결 문자열로 바꿉니다(Azure AI 파운드리 포털의 프로젝트 **개요** 페이지에서 복사함).
    1. **your_model_deployment** 자리 표시자를 GPT-4o 모델 배포에 할당한 이름(기본값으로 `gpt-4o`)으로 바꿉니다.

1. 자리 표시자를 바꾼 *후* 코드 편집기에서 **CTRL+S** 명령 또는 **마우스 오른쪽 단추 클릭 > 저장**을 사용하여 **변경 내용을 저장**한 다음, **CTRL+Q** 명령 또는 **마우스 오른쪽 단추 클릭 > 끝내기**를 사용하여 Cloud Shell 명령줄을 열어둔 채 코드 편집기를 닫습니다.

### 배포된 모델에 프롬프트 보내기

이제 배포된 모델에 다른 프롬프트를 보내는 여러 스크립트를 실행합니다. 이러한 상호 작용은 나중에 Azure Monitor에서 관찰할 수 있는 데이터를 생성합니다.

1. 제공된 **첫 번째 스크립트를 보려면** 다음 명령을 실행합니다.

    ```
   code start-prompt.py
    ```

1. 코드 편집기 아래의 Cloud Shell 명령줄 창에서 다음 명령을 입력하여 **스크립트를 실행**합니다.

    ```
   python start-prompt.py
    ```

    모델은 추가 분석을 위해 Application Insights로 캡처되는 응답을 생성합니다. 프롬프트를 변경하여 효과를 살펴보겠습니다.

1. **스크립트를 열고 검토합니다**. 여기서 프롬프트는 **한 문장과 목록으로만 응답**하도록 모델에 지시합니다.

    ```
   code short-prompt.py
    ```

1. 명령줄에서 다음 명령을 입력하여 **스크립트를 실행합니다**.

    ```
   python short-prompt.py
    ```

1. 다음 스크립트는 비슷한 목표를 가지고 있지만 사용자 메시지 대신 **시스템 메시지**의 출력에 대한 지침을 포함합니다.

    ```
   code system-prompt.py
    ```

1. 명령줄에서 다음 명령을 입력하여 **스크립트를 실행합니다**.

    ```
   python system-prompt.py
    ```

1. 마지막으로 **토큰이 너무 많은** 프롬프트를 실행하여 오류를 트리거해 보겠습니다.

    ```
   code error-prompt.py
    ```

1. 명령줄에 다음 명령을 입력하여 **스크립트를 실행**합니다. **오류가 발생할 가능성이 매우 높습니다!**

    ```
   python error-prompt.py
    ```

이제 모델과 상호 작용했으므로 Azure Monitor에서 데이터를 검토할 수 있습니다.

> **참고**: 모니터링 데이터가 Azure Monitor에 표시되는 데 몇 분 정도 걸릴 수 있습니다.

## Azure Monitor에서 모니터링 데이터 보기

모델 상호 작용에서 수집된 데이터를 보려면 Azure Monitor의 통합 문서에 연결되는 대시보드에 액세스합니다.

### Azure AI 파운드리 포털에서 Azure Monitor로 이동합니다.

1. **Azure AI 파운드리 포털**이 열려 있는 브라우저의 탭으로 이동합니다.
1. 왼쪽 메뉴에서 **추적**을 선택합니다.
1. 맨 위에 있는 **생성형 AI 애플리케이션 대시보드에 대한 인사이트를 확인합니다**라는 링크를 선택합니다. 이 링크는 새 탭에서 Azure Monitor를 엽니다.
1. 배포된 모델과의 상호작용에 대한 요약된 데이터를 제공하는 **개요**를 검토합니다.

## Azure Monitor에서 모니터링 메트릭 해석

이제 데이터를 자세히 알아보고 데이터가 알려주는 내용을 해석할 차례입니다.

### 토큰 사용량 검토

먼저 **토큰 사용량** 섹션에 초점을 맞추고 다음 메트릭을 검토합니다.

- **프롬프트 토큰**: 모든 모델 호출에서 입력(보낸 프롬프트)에 사용된 총 토큰 수입니다.

> 이를 모델에게 *질문하는 데 드는 비용*으로 간주하면 됩니다.

- **완료 토큰**: 모델이 출력으로 반환한 토큰 수, 기본적으로 응답 길이입니다.

> 생성된 완료 토큰은 특히 길거나 자세한 답변의 경우 토큰 사용량과 비용의 대부분을 나타내는 경우가 많습니다.

- **총 토큰**: 총 프롬프트 토큰과 완료 토큰을 결합한 것입니다.

> 대기 시간 및 비용을 증가시키므로 청구 및 성능 측면에서 가장 중요한 메트릭입니다.

- **총 호출**: 모델이 호출된 횟수인 별도의 유추 요청 수입니다.

> 처리량을 분석하고 호출당 평균 비용을 이해하는 데 유용합니다.

### 개별 프롬프트 비교

아래로 스크롤하여 각 프롬프트가 새로운 데이터 행으로 표시되는 테이블로 시각화되는 **Gen AI 범위**를 찾습니다. 다음 열의 내용을 검토하고 비교합니다.

- **상태**: 모델 호출이 성공했는지 또는 실패했는지 여부입니다.

> 이를 사용하여 문제가 있는 프롬프트나 구성 오류를 식별합니다. 프롬프트가 너무 길어서 마지막 프롬프트가 실패했을 가능성이 높습니다.

- **기간**: 모델이 응답하는 데 걸린 시간을 밀리초로 표시합니다.

> 여러 행을 비교하여 처리 시간이 더 길어지는 프롬프트 패턴을 탐색합니다.

- **입력**: 모델로 전송된 사용자 메시지를 표시합니다.

> 이 열을 사용하여 어떤 프롬프트 공식이 효율적이거나 문제가 있는지 평가합니다.

- **시스템**: 프롬프트에 사용된 시스템 메시지를 표시합니다(있는 경우).

> 항목을 비교하여 시스템 메시지 사용 또는 변경의 영향을 평가합니다.

- **출력**: 모델의 응답을 포함합니다.

> 세부 정보 표시, 관련성 및 일관성을 평가하는 데 사용합니다. 특히 토큰 수 및 기간과 관련이 있습니다.

## (선택 사항) 경고 만들기

시간이 남는 경우 모델 대기 시간이 특정 임계값을 초과할 때 알림을 보내도록 경고를 설정해 봅니다. 이것은 사용자가 도전하기 위해 고안된 연습이며 지침이 의도적으로 상세하게 설명되어 있지 않습니다.

- Azure Monitor에서 Azure AI 파운드리 프로젝트 및 모델에 대한 **새 경고 규칙**을 만듭니다.
- **요청 기간(ms)** 과 같은 메트릭을 선택하고 임계값(예: 4000ms 초과)을 정의합니다.
- 알림을 받는 방법을 정의하려면 **새 작업 그룹**을 만듭니다.

경고를 통해 사전 모니터링을 설정하여 프로덕션에 준비할 수 있습니다. 구성하는 경고는 프로젝트의 우선 순위와 팀이 위험을 측정하고 완화하기로 결정한 방법에 따라 달라집니다.

## 다른 랩을 찾을 수 있는 위치

[Azure AI 파운드리 학습 포털](https://ai.azure.com)에서 추가 랩 및 연습을 탐색하거나 해당 과정의 **랩 섹션**에서 제공되는 다른 활동을 참조할 수 있습니다.
